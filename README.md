# ğŸ… Olympic Data Analysis with Azure Data Engineering

## ğŸ“Œ Overview
This project presents an **end-to-end analysis** of **Olympic data** using **Azure Data Factory, Azure Data Lake Gen 2, Azure Synapse Analytics, and Azure Databricks**. The objective is to demonstrate **modern data engineering techniques** for efficient **data ingestion, transformation, and analysis**.

### ğŸ”¹ **Key Insights & Business Impact**
âœ… **Medal Trends Over Time** â€“ Identify historical patterns in Olympic performances.  
âœ… **Athlete Performance Analysis** â€“ Evaluate top-performing athletes across events.  
âœ… **Country-Wise Achievements** â€“ Compare medal distributions across nations.  
âœ… **Scalable Data Pipeline** â€“ Implements best practices in **Azure data engineering**.  


## ğŸ”„ Data Pipeline Steps

### **1ï¸âƒ£ Data Ingestion with Azure Data Factory**
- Used **Azure Data Factory (ADF) Pipelines** to **ingest Olympic data**.
- Loaded raw CSV files into **Azure Data Lake Storage Gen 2**.

### **2ï¸âƒ£ Data Transformation with Azure Databricks (PySpark)**
- Cleaned and pre-processed data using **PySpark in Azure Databricks**.
- Handled **missing values, data formatting, and schema standardization**.
- Saved **transformed data** back to **Azure Data Lake Gen 2**.

### **3ï¸âƒ£ Data Querying with Azure Synapse Analytics**
- Loaded processed data into **Azure Synapse Analytics**.
- Ran **SQL queries** to analyze **medal counts, top-performing countries, and athlete trends**.

### **4ï¸âƒ£ Visualizing Insights**
- Connected **Power BI** to **Azure Synapse** for **interactive dashboards**.
