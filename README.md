# 🏅 Olympic Data Analysis with Azure Data Engineering

## 📌 Overview
This project presents an **end-to-end analysis** of **Olympic data** using **Azure Data Factory, Azure Data Lake Gen 2, Azure Synapse Analytics, and Azure Databricks**. The objective is to demonstrate **modern data engineering techniques** for efficient **data ingestion, transformation, and analysis**.

### 🔹 **Key Insights & Business Impact**
✅ **Medal Trends Over Time** – Identify historical patterns in Olympic performances.  
✅ **Athlete Performance Analysis** – Evaluate top-performing athletes across events.  
✅ **Country-Wise Achievements** – Compare medal distributions across nations.  
✅ **Scalable Data Pipeline** – Implements best practices in **Azure data engineering**.  


## 🔄 Data Pipeline Steps

### **1️⃣ Data Ingestion with Azure Data Factory**
- Used **Azure Data Factory (ADF) Pipelines** to **ingest Olympic data**.
- Loaded raw CSV files into **Azure Data Lake Storage Gen 2**.

### **2️⃣ Data Transformation with Azure Databricks (PySpark)**
- Cleaned and pre-processed data using **PySpark in Azure Databricks**.
- Handled **missing values, data formatting, and schema standardization**.
- Saved **transformed data** back to **Azure Data Lake Gen 2**.

### **3️⃣ Data Querying with Azure Synapse Analytics**
- Loaded processed data into **Azure Synapse Analytics**.
- Ran **SQL queries** to analyze **medal counts, top-performing countries, and athlete trends**.

### **4️⃣ Visualizing Insights**
- Connected **Power BI** to **Azure Synapse** for **interactive dashboards**.
